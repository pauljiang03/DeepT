# Robustness Verification for Transformers

This repo is for the code of our work:
Anonymous Authors: "DeepT: Fast and Scalable Robustness Certification for Transformers"

We also include the scripts to run our experiments and well the pretrained networks and the used vocabularies.
We also include the synonym data provided in "Automatic Perturbation Analysis for Scalable Certified Robustness and Beyond"
which follows the Alzantot attack in order to run our certification method against synonym attacks.

We include the code from
 - Zhouxing Shi, Huan Zhang, Kai-Wei Chang, Minlie Huang, Cho-Jui Hsieh. Robustness Verification for Transformers. ICLR 2020.
 - Kaidi Xu, Zhouxing Shi, Huan Zhang, Yihan Wang, Kai-Wei Chang, Minlie Huang, Bhavya Kailkhura, Xue Lin, Cho-Jui Hsieh. Automatic Perturbation Analysis for Scalable Certified Robustness and Beyond
used to perform comparisons and to use their certifiability-pretrained network.
Some files in this folder will include the appropriate copyright header citing those authors, 
but these files may have been extended by us. 


